{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27ddeb2c-7877-46e3-9a4e-b2efb0d1b7a4",
   "metadata": {},
   "source": [
    "# How to optimize the Meta Llama-3 70B Amazon JumpStart model for inference using Amazon SageMaker model optimization jobs\n",
    "**Recommended kernel(s):** This notebook can be run with any Amazon SageMaker Studio kernel.\n",
    "\n",
    "In this notebook, you will learn how to apply state-of-the-art optimization techniques to an Amazon JumpStart model (JumpStart model ID: `meta-textgeneration-llama-3-70b`) using Amazon SageMaker ahead-of-time (AOT) model optimization capabilities. Each example includes the deployment of the optimized model to an Amazon SageMaker endpoint. In all cases, the inference image will be the SageMaker-managed [LMI (Large Model Inference)](https://docs.aws.amazon.com/sagemaker/latest/dg/large-model-inference-container-docs.html) Docker image. LMI images features a [DJL serving](https://github.com/deepjavalibrary/djl-serving) stack powered by the [Deep Java Library](https://djl.ai/). \n",
    "\n",
    "You will successively:\n",
    "1. Deploy a pre-optimized variant of the Amazon JumpStart model with speculative decoding enabled (using SageMaker provided draft model). For popular models, the JumpStart team indeed selects and applies the best optimization configurations for you.\n",
    "\n",
    "\n",
    "**Notices:**\n",
    "* Make sure that the `ml.p4d.24xlarge` and `ml.inf2.48xlarge` instance types required for the tutorials are available in your AWS Region.\n",
    "* Make sure that the value of your \"ml.p4d.24xlarge for endpoint usage\" and \"ml.inf2.48xlarge for endpoint usage\" Amazon SageMaker service quotas allow you to deploy at least one Amazon SageMaker endpoint using these instance types.\n",
    "\n",
    "This notebook leverages the [Model Builder Class](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-modelbuilder-creation.html) within the [`sagemaker` Python SDK](https://sagemaker.readthedocs.io/en/stable/index.html) to abstract out container and model server management/tuning. Via the Model Builder Class you can easily interact with JumpStart Models, HuggingFace Hub Models, and also custom models via pointing towards an S3 path with your Model Data. For this sample we will focus on the JumpStart Optimization path.\n",
    "\n",
    "### License agreement\n",
    "* This model is under the Meta license, please refer to the original model card.\n",
    "* This notebook is a sample notebook and not intended for production use.\n",
    "\n",
    "### Execution environment setup\n",
    "This notebook requires the following third-party Python dependencies:\n",
    "* AWS [`boto3`](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html#)\n",
    "* AWS [`sagemaker`](https://sagemaker.readthedocs.io/en/stable/index.html) with a version greater than or equal to 2.225.0 \n",
    "\n",
    "Let's install or upgrade these dependencies using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a645403-0c3e-4062-9d16-ef0b1041fbe3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.33.24 requires botocore==1.34.142, but you have botocore 1.34.150 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sagemaker>=2.225.0 boto3 huggingface_hub --upgrade --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5631d3-1c16-4ad5-a42c-85a28cf9dd3e",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65310881-31a9-453e-9f7b-c79876824cd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from sagemaker.serve.builder.model_builder import ModelBuilder\n",
    "from sagemaker.serve.builder.schema_builder import SchemaBuilder\n",
    "from sagemaker.session import Session\n",
    "import logging\n",
    "import huggingface_hub\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d22b6d0b-5c6c-4014-b836-df0268e11feb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sagemaker_session = Session()\n",
    "\n",
    "artifacts_bucket_name = sagemaker_session.default_bucket()\n",
    "execution_role_arn = sagemaker_session.get_caller_identity_arn()\n",
    "\n",
    "js_model_id = \"meta-textgeneration-llama-3-70b\"\n",
    "gpu_instance_type = \"ml.p4d.24xlarge\"\n",
    "neuron_instance_type = \"ml.inf2.48xlarge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1eb26871-315d-425f-a5d2-b05627191700",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = \"Hello, I'm a language model, and I'm here to help you with your English.\"\n",
    "\n",
    "sample_input = {\n",
    "    \"inputs\": \"Hello, I'm a language model,\",\n",
    "    \"parameters\": {\"max_new_tokens\": 128, \"top_p\": 0.9, \"temperature\": 0.6},\n",
    "}\n",
    "\n",
    "sample_output = [{\"generated_text\": response}]\n",
    "\n",
    "schema_builder = SchemaBuilder(sample_input, sample_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81838b96-ca02-4892-b861-8cb0634fb167",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Deploy a pre-optimized deployment configuration with speculative decoding (SageMaker provided draft model)\n",
    "The `meta-textgeneration-llama-3-70b` JumpStart model is available with multiple pre-optimized deployment configuration. Optimized model artifacts for each configuration have already been created by the JumpStart team and a readily available for deployment. In this section, you will deploy one of theses pre-optimized configuration to an Amazon SageMaker endpoint. \n",
    "\n",
    "### What is speculative decoding?\n",
    "Speculative decoding is an inference optimization technique introduced by [Y. Leviathan et al. (ICML 2023)](https://arxiv.org/abs/2211.17192) used to accelerate the decoding process of large and therefore slow LLMs for latency-critical applications. The key idea is to use a smaller, less powerful but faster model called the ***draft model*** to generate candidate tokens that get validated by the larger, more powerful but slower model called the ***target model***. At each iteration, the draft model generates $K>1$ candidate tokens. Then, using a single forward pass of the larger target model, none, part, or all candidate tokens get accepted. The more aligned the selected draft model is with the target model, the better guesses it makes, the higher candidate token acceptance rate and therefore the higher the speed ups. The larger the size gap between the target and the draft model, the largest the potential speedups.\n",
    "\n",
    "Let's start by creating a `ModelBuilder` instance for the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f490309f-da98-4489-8bab-d1ffde767370",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_builder = ModelBuilder(\n",
    "    model=js_model_id,\n",
    "    schema_builder=schema_builder,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    role_arn=execution_role_arn,\n",
    "    log_level=logging.ERROR\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294805b8-f056-4a24-9d10-df32039d1193",
   "metadata": {},
   "source": [
    "For each optimization configuration, the JumpStart team has computed key performance metrics such as time-to-first-token (TTFT) latency and throughput for multiple hardwares and concurrent invocation intensities. Let's visualize these metrics using the `display_benchmark_metrics` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2eedd83-3104-4820-bb5c-6164b9d0477f",
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model 'meta-textgeneration-llama-3-70b' requires accepting end-user license agreement (EULA). See https://jumpstart-cache-prod-us-east-1.s3.us-east-1.amazonaws.com/fmhMetadata/eula/llama3Eula.txt for terms of use.\n",
      "INFO:sagemaker.jumpstart:Model 'meta-textgeneration-llama-3-70b' requires accepting end-user license agreement (EULA). See https://jumpstart-cache-prod-us-east-1.s3.us-east-1.amazonaws.com/fmhMetadata/eula/llama3Eula.txt for terms of use.\n",
      "Using model 'meta-textgeneration-llama-3-70b' with wildcard version identifier '*'. You can pin to version '2.2.1' for more stable results. Note that models may have different input/output signatures after a major version upgrade.\n",
      "WARNING:sagemaker.jumpstart:Using model 'meta-textgeneration-llama-3-70b' with wildcard version identifier '*'. You can pin to version '2.2.1' for more stable results. Note that models may have different input/output signatures after a major version upgrade.\n",
      "No instance type selected for inference hosting endpoint. Defaulting to ml.p4d.24xlarge.\n",
      "INFO:sagemaker.jumpstart:No instance type selected for inference hosting endpoint. Defaulting to ml.p4d.24xlarge.\n",
      "ModelBuilder: INFO:     JumpStart ID meta-textgeneration-llama-3-70b is packaged with Image URI: 763104351884.dkr.ecr.us-east-1.amazonaws.com/djl-inference:0.28.0-lmi10.0.0-cu124\n",
      "ModelBuilder: INFO:     Building for DJL JumpStart Model ID...\n",
      "ModelBuilder: WARNING:     57.176819782242106 percent of disk space used. Please consider freeing up disk space or increasing the EBS volume if you are on a SageMaker Notebook.\n",
      "ModelBuilder: WARNING:     57.176819782242106 percent of docker disk space at /var/lib/docker is used. Please consider freeing up disk space or increasing the EBS volume if you are on a SageMaker Notebook.\n",
      "Instance rate metrics will be omitted. Reason: User: arn:aws:sts::969468890356:assumed-role/mlopt3/SageMaker is not authorized to perform: pricing:GetProducts because no identity-based policy allows the pricing:GetProducts action\n",
      "WARNING:sagemaker.jumpstart:Instance rate metrics will be omitted. Reason: User: arn:aws:sts::969468890356:assumed-role/mlopt3/SageMaker is not authorized to perform: pricing:GetProducts because no identity-based policy allows the pricing:GetProducts action\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Instance Type             | Config Name   |   Concurrent Users |   Latency, TTFT (P50 in sec) |   Throughput (P50 in tokens/sec/user) |\n",
      "|:--------------------------|:--------------|-------------------:|-----------------------------:|--------------------------------------:|\n",
      "| ml.g5.48xlarge            | lmi           |                  1 |                         2.02 |                                 18.80 |\n",
      "| ml.g5.48xlarge            | lmi           |                  2 |                         2.10 |                                 15.40 |\n",
      "| ml.g5.48xlarge            | lmi           |                  4 |                         2.15 |                                  9.40 |\n",
      "| ml.g5.48xlarge            | lmi           |                  8 |                         2.93 |                                  6.70 |\n",
      "| ml.p4d.24xlarge           | lmi           |                 64 |                         0.20 |                                  9.70 |\n",
      "| ml.p4d.24xlarge           | lmi           |                128 |                         4.01 |                                  8.10 |\n",
      "| ml.p4d.24xlarge (Default) | lmi           |                  1 |                         0.10 |                                 44.70 |\n",
      "| ml.p4d.24xlarge           | lmi           |                  2 |                         0.11 |                                 41.00 |\n",
      "| ml.p4d.24xlarge           | lmi           |                  4 |                         0.12 |                                 36.90 |\n",
      "| ml.p4d.24xlarge           | lmi           |                  8 |                         0.12 |                                 30.60 |\n",
      "| ml.p4d.24xlarge           | lmi           |                 16 |                         0.13 |                                 23.20 |\n",
      "| ml.p4d.24xlarge           | lmi           |                 32 |                         0.15 |                                 15.70 |\n",
      "| ml.p5.48xlarge            | lmi           |                 64 |                         0.10 |                                 18.30 |\n",
      "| ml.p5.48xlarge            | lmi           |                128 |                         0.12 |                                 11.50 |\n",
      "| ml.p5.48xlarge            | lmi           |                256 |                         3.33 |                                 10.00 |\n",
      "| ml.p5.48xlarge            | lmi           |                  1 |                         0.08 |                                 48.20 |\n",
      "| ml.p5.48xlarge            | lmi           |                  2 |                         0.08 |                                 48.20 |\n",
      "| ml.p5.48xlarge            | lmi           |                  4 |                         0.08 |                                 46.60 |\n",
      "| ml.p5.48xlarge            | lmi           |                  8 |                         0.09 |                                 43.50 |\n",
      "| ml.p5.48xlarge            | lmi           |                 16 |                         0.09 |                                 37.30 |\n",
      "| ml.p5.48xlarge            | lmi           |                 32 |                         0.09 |                                 29.20 |\n",
      "| ml.g5.48xlarge            | lmi-optimized |                  1 |                         2.25 |                                 49.70 |\n",
      "| ml.g5.48xlarge            | lmi-optimized |                  2 |                         2.28 |                                 21.10 |\n",
      "| ml.g5.48xlarge            | lmi-optimized |                  4 |                         2.37 |                                 14.10 |\n",
      "| ml.g5.48xlarge            | lmi-optimized |                  8 |                         2.48 |                                  7.90 |\n",
      "| ml.g6.48xlarge            | lmi-optimized |                  1 |                         0.95 |                                 31.30 |\n",
      "| ml.g6.48xlarge            | lmi-optimized |                  2 |                         1.03 |                                 17.90 |\n",
      "| ml.g6.48xlarge            | lmi-optimized |                  4 |                         1.08 |                                 15.20 |\n",
      "| ml.g6.48xlarge            | lmi-optimized |                  8 |                         1.18 |                                  9.80 |\n",
      "| ml.g6.48xlarge            | lmi-optimized |                 16 |                         1.92 |                                  5.20 |\n",
      "| ml.p4d.24xlarge           | lmi-optimized |                  1 |                         0.10 |                                137.40 |\n",
      "| ml.p4d.24xlarge           | lmi-optimized |                  2 |                         0.11 |                                109.20 |\n",
      "| ml.p4d.24xlarge           | lmi-optimized |                  4 |                         0.13 |                                 85.00 |\n",
      "| ml.p4d.24xlarge           | lmi-optimized |                  8 |                         0.13 |                                 60.30 |\n",
      "| ml.p4d.24xlarge           | lmi-optimized |                 16 |                         0.16 |                                 40.30 |\n",
      "| ml.p4d.24xlarge           | lmi-optimized |                 32 |                         0.20 |                                 23.60 |\n",
      "| ml.p4d.24xlarge           | lmi-optimized |                 64 |                         0.29 |                                 12.90 |\n",
      "| ml.p4d.24xlarge           | lmi-optimized |                128 |                         3.76 |                                 10.70 |\n",
      "| ml.p5.48xlarge            | lmi-optimized |                  1 |                         0.08 |                                136.40 |\n",
      "| ml.p5.48xlarge            | lmi-optimized |                  2 |                         0.08 |                                152.00 |\n",
      "| ml.p5.48xlarge            | lmi-optimized |                  4 |                         0.08 |                                134.20 |\n",
      "| ml.p5.48xlarge            | lmi-optimized |                  8 |                         0.09 |                                119.00 |\n",
      "| ml.p5.48xlarge            | lmi-optimized |                 16 |                         0.09 |                                 89.40 |\n",
      "| ml.p5.48xlarge            | lmi-optimized |                 32 |                         0.10 |                                 61.80 |\n",
      "| ml.p5.48xlarge            | lmi-optimized |                 64 |                         0.11 |                                 37.70 |\n",
      "| ml.p5.48xlarge            | lmi-optimized |                128 |                         0.15 |                                 18.30 |\n",
      "| ml.p5.48xlarge            | lmi-optimized |                256 |                         1.88 |                                 17.70 |\n",
      "| ml.p5.48xlarge            | lmi-optimized |                512 |                         3.76 |                                 51.10 |\n"
     ]
    }
   ],
   "source": [
    "model_builder.display_benchmark_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f84c42-d578-4136-9e86-34058e134707",
   "metadata": {},
   "source": [
    "Now, let's pick and deploy the `lmi-optimized` pre-optimized configuration to a `ml.p4d.24xlarge` instance. The `lmi-optimized` configuration enables speculative decoding. In this configuration, a SageMaker provided draft model is used. Therefore, you don't have to supply a draft model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e9bb346-4108-4721-86bc-c754d59c4bf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_builder.set_deployment_config(config_name=\"lmi-optimized\", instance_type=\"ml.g5.48xlarge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35232c11-eb78-4521-ae60-243bdc7e1666",
   "metadata": {},
   "source": [
    "Currently set deployment configuration can be visualized using the `get_deployment_config` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb8e44a7-cce1-4417-b701-6895638fa42e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model 'meta-textgeneration-llama-3-70b' requires accepting end-user license agreement (EULA). See https://jumpstart-cache-prod-us-east-1.s3.us-east-1.amazonaws.com/fmhMetadata/eula/llama3Eula.txt for terms of use.\n",
      "INFO:sagemaker.jumpstart:Model 'meta-textgeneration-llama-3-70b' requires accepting end-user license agreement (EULA). See https://jumpstart-cache-prod-us-east-1.s3.us-east-1.amazonaws.com/fmhMetadata/eula/llama3Eula.txt for terms of use.\n",
      "Using model 'meta-textgeneration-llama-3-70b' with wildcard version identifier '*'. You can pin to version '2.2.1' for more stable results. Note that models may have different input/output signatures after a major version upgrade.\n",
      "WARNING:sagemaker.jumpstart:Using model 'meta-textgeneration-llama-3-70b' with wildcard version identifier '*'. You can pin to version '2.2.1' for more stable results. Note that models may have different input/output signatures after a major version upgrade.\n",
      "Instance rate metrics will be omitted. Reason: User: arn:aws:sts::969468890356:assumed-role/mlopt3/SageMaker is not authorized to perform: pricing:GetProducts because no identity-based policy allows the pricing:GetProducts action\n",
      "WARNING:sagemaker.jumpstart:Instance rate metrics will be omitted. Reason: User: arn:aws:sts::969468890356:assumed-role/mlopt3/SageMaker is not authorized to perform: pricing:GetProducts because no identity-based policy allows the pricing:GetProducts action\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'DeploymentConfigName': 'lmi-optimized',\n",
       " 'DeploymentArgs': {'ImageUri': '763104351884.dkr.ecr.us-east-1.amazonaws.com/djl-inference:0.28.0-lmi10.0.0-cu124',\n",
       "  'ModelData': {'S3DataSource': {'S3Uri': 's3://jumpstart-private-cache-prod-us-east-1/meta-textgeneration/meta-textgeneration-llama-3-70b/artifacts/inference-prepack/v1.1.0/',\n",
       "    'S3DataType': 'S3Prefix',\n",
       "    'CompressionType': 'None'}},\n",
       "  'ModelPackageArn': None,\n",
       "  'Environment': {'SAGEMAKER_PROGRAM': 'inference.py',\n",
       "   'ENDPOINT_SERVER_TIMEOUT': '3600',\n",
       "   'MODEL_CACHE_ROOT': '/opt/ml/model',\n",
       "   'SAGEMAKER_ENV': '1',\n",
       "   'HF_MODEL_ID': '/opt/ml/model',\n",
       "   'OPTION_SPECULATIVE_DRAFT_MODEL': '/opt/ml/additional-model-data-sources/draft_model',\n",
       "   'SAGEMAKER_MODEL_SERVER_WORKERS': '1'},\n",
       "  'InstanceType': 'ml.g5.48xlarge',\n",
       "  'ComputeResourceRequirements': {'MinMemoryRequiredInMb': 393216,\n",
       "   'NumberOfAcceleratorDevicesRequired': 8},\n",
       "  'ModelDataDownloadTimeout': 1200,\n",
       "  'ContainerStartupHealthCheckTimeout': 1200,\n",
       "  'AdditionalDataSources': {'speculative_decoding': [{'channel_name': 'draft_model',\n",
       "     'artifact_version': 'v3',\n",
       "     's3_data_source': {'compression_type': 'None',\n",
       "      's3_data_type': 'S3Prefix',\n",
       "      's3_uri': 'sagemaker-speculative-decoding-llama3-small-v3/'}}]}},\n",
       " 'AccelerationConfigs': [{'type': 'Compilation', 'enabled': False},\n",
       "  {'type': 'Speculative-Decoding', 'enabled': True},\n",
       "  {'type': 'Quantization', 'enabled': False}],\n",
       " 'BenchmarkMetrics': {'ml.g5.48xlarge': [{'name': 'Latency',\n",
       "    'value': '2.25',\n",
       "    'unit': 'sec',\n",
       "    'concurrency': '1'},\n",
       "   {'name': 'Throughput',\n",
       "    'value': '49.7',\n",
       "    'unit': 'tokens/sec',\n",
       "    'concurrency': '1'},\n",
       "   {'name': 'Latency', 'value': '2.28', 'unit': 'sec', 'concurrency': '2'},\n",
       "   {'name': 'Throughput',\n",
       "    'value': '21.1',\n",
       "    'unit': 'tokens/sec',\n",
       "    'concurrency': '2'},\n",
       "   {'name': 'Latency', 'value': '2.37', 'unit': 'sec', 'concurrency': '4'},\n",
       "   {'name': 'Throughput',\n",
       "    'value': '14.1',\n",
       "    'unit': 'tokens/sec',\n",
       "    'concurrency': '4'},\n",
       "   {'name': 'Latency', 'value': '2.48', 'unit': 'sec', 'concurrency': '8'},\n",
       "   {'name': 'Throughput',\n",
       "    'value': '7.9',\n",
       "    'unit': 'tokens/sec',\n",
       "    'concurrency': '8'}]}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_builder.get_deployment_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad37a7b-e2cc-45af-bf27-ea6c1aa258ba",
   "metadata": {},
   "source": [
    "Now, let's build the `Model` instance and use it to deploy the selected optimized configuration. This operation may take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "972aea37-4a16-4eee-b3ad-33b1077cbcbc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ModelBuilder: INFO:     Either inference spec or model is provided. ModelBuilder is not handling MLflow model input\n",
      "Model 'meta-textgeneration-llama-3-70b' requires accepting end-user license agreement (EULA). See https://jumpstart-cache-prod-us-east-1.s3.us-east-1.amazonaws.com/fmhMetadata/eula/llama3Eula.txt for terms of use.\n",
      "INFO:sagemaker.jumpstart:Model 'meta-textgeneration-llama-3-70b' requires accepting end-user license agreement (EULA). See https://jumpstart-cache-prod-us-east-1.s3.us-east-1.amazonaws.com/fmhMetadata/eula/llama3Eula.txt for terms of use.\n",
      "Using model 'meta-textgeneration-llama-3-70b' with wildcard version identifier '*'. You can pin to version '2.2.1' for more stable results. Note that models may have different input/output signatures after a major version upgrade.\n",
      "WARNING:sagemaker.jumpstart:Using model 'meta-textgeneration-llama-3-70b' with wildcard version identifier '*'. You can pin to version '2.2.1' for more stable results. Note that models may have different input/output signatures after a major version upgrade.\n",
      "ModelBuilder: INFO:     JumpStart Model ID detected.\n",
      "ModelBuilder: INFO:     JumpStart Model ID detected.\n"
     ]
    }
   ],
   "source": [
    "optimized_model = model_builder.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27a2527-a189-4b26-b579-bae031f69248",
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ModelBuilder: INFO:     ModelBuilder will collect telemetry to help us better understand our user's needs, diagnose issues, and deliver additional features. To opt out of telemetry, please disable via TelemetryOptOut in intelligent defaults. See https://sagemaker.readthedocs.io/en/stable/overview.html#configuring-and-using-defaults-with-the-sagemaker-python-sdk for more info.\n",
      "INFO:sagemaker:Creating model with name: meta-textgeneration-llama-3-70b-2024-07-29-20-58-58-076\n",
      "WARNING:sagemaker:Using already existing model: meta-textgeneration-llama-3-70b-2024-07-29-20-58-58-076\n",
      "INFO:sagemaker:Creating endpoint-config with name meta-textgeneration-llama-3-70b-2024-07-30-01-03-20-173\n",
      "INFO:sagemaker:Creating endpoint with name meta-textgeneration-llama-3-70b-2024-07-30-01-03-20-173\n",
      "WARNING:sagemaker:Failed to enable live logging: An error occurred (AccessDeniedException) when calling the FilterLogEvents operation: User: arn:aws:sts::969468890356:assumed-role/mlopt3/SageMaker is not authorized to perform: logs:FilterLogEvents on resource: arn:aws:logs:us-east-1:969468890356:log-group:/aws/sagemaker/Endpoints/meta-textgeneration-llama-3-70b-2024-07-30-01-03-20-173:log-stream: because no identity-based policy allows the logs:FilterLogEvents action. Fallback to default logging...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------"
     ]
    }
   ],
   "source": [
    "predictor = optimized_model.deploy(accept_eula=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e7fb08-3ff0-40c5-8a4e-9a026d7fba62",
   "metadata": {},
   "source": [
    "Once the deployment has finished successfully, you can send queries to the model by simply using the predictor's `predict` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa8249e-9e8a-48d1-9dd2-2a31d664d954",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor.predict(sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7984819c-e3ec-47d9-92a8-d91fa4998b55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Clean up\n",
    "predictor.delete_model()\n",
    "predictor.delete_endpoint(delete_endpoint_config=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
